# ğŸ“¦ Sentiment-Analysis-on-IMDB-Reviews
Build a text classifier that can detect positive vs negative sentiment from short user reviews

## ğŸš€ Project Overview
- **Objective:** Classify movie or tweet reviews into positive or negative sentiment
- **Approach:** Preprocess text, extract TF-IDF features (unigram and bigrams) and train a supervised ML model
- **Highlight:** Bigram feature engineering improved F1 score from **89% to 94%**

## ğŸ“ Dataset
- ğŸ“‚ **Source:** [IMDB Movie Reviews](https://ai.stanford.edu/~amaas/data/sentiment/)  
 _(Alternatively: [Sentiment140 (Twitter)](https://www.kaggle.com/datasets/kazanova/sentiment140))_
- ğŸ‘¥ Binary sentiment: `positive` (1), `negative` (0)
- ğŸ§® Preprocessed to remove HTML tags, special characters, stopwords, and lowercase everything.


## ğŸ§ª Model Pipeline
| Step | Details |
|------|---------|
| ğŸ”¹ Preprocessing | Cleaning, stopword removal, optional lemmatization |
| ğŸ”¹ Feature Extraction | `TfidfVectorizer(ngram_range=(1, 2))` |
| ğŸ”¹ Model | Logistic Regression |
| ğŸ”¹ Evaluation | Accuracy, Precision, Recall, F1-Score, Confusion Matrix |


## ğŸ“Š Results
| Metric | Score |
|--------|-------|
| Accuracy | 94.1% |
| Precision | 93.7% |
| Recall | 94.3% |
| F1 Score | 94.0% |

ğŸ“ˆ **Improvement:**  
- F1 score increased from **89% â†’ 94%** after switching from unigrams to **bigrams**, which captured key sentiment phrases like `"not good"`, `"very bad"`, and `"absolutely loved"`.
---
## ğŸ§  Key Learnings
- Bigrams significantly improve sentiment classification by capturing short, meaningful phrases.
- Error analysis helped identify failures with negations and sarcasm.
- Logistic Regression with TF-IDF still performs strongly on clean binary sentiment tasks.
---


**Part of my 20-Day NLP Spring Day#3**